{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from skimage import filters\n","from sklearn.decomposition import PCA\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.svm import SVC\n","\n","# 1. Image Pre-processing\n","def image_preprocessing(image, target_size=(256, 256)):\n","    resized_image = cv2.resize(image, target_size)\n","    denoised_image = cv2.medianBlur(resized_image, 5)  # Applying median filter for denoising\n","    return denoised_image\n","\n","# 2. Image Segmentation\n","def watershed_segmentation(image):\n","    # Convert the image to BGR color space\n","    bgr_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply thresholding to obtain a binary image\n","    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","\n","    # Perform morphological operations to remove noise\n","    kernel = np.ones((3,3), np.uint8)\n","    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n","\n","    # Find sure background area\n","    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n","\n","    # Find sure foreground area\n","    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n","    ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n","\n","    # Find unknown region\n","    sure_fg = np.uint8(sure_fg)\n","    unknown = cv2.subtract(sure_bg, sure_fg)\n","\n","    # Marker labelling\n","    ret, markers = cv2.connectedComponents(sure_fg)\n","    markers = markers + 1\n","    markers[unknown == 255] = 0\n","\n","    # Apply watershed algorithm\n","    markers = cv2.watershed(bgr_image, markers)\n","    segmented_image = bgr_image.copy()  # Copy the original image for marking boundaries\n","    segmented_image[markers == -1] = [255,0,0]  # Mark watershed boundaries\n","\n","    return segmented_image\n","\n","\n","# 3. Image Feature Extraction\n","def gabor_features(image):\n","    # Define parameters for Gabor filter\n","    ksize = 31  # Size of Gabor filter (odd number)\n","    sigma = 4   # Standard deviation of the Gaussian envelope\n","    theta = np.pi / 4  # Orientation of the normal to the parallel stripes of a Gabor function\n","    lambd = 10  # Wavelength of the sinusoidal factor\n","    gamma = 0.5  # Spatial aspect ratio\n","\n","    # Create Gabor filter kernel\n","    gabor_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)\n","\n","    # Apply Gabor filter to the image\n","    filtered_image = cv2.filter2D(image, cv2.CV_8UC3, gabor_kernel)\n","\n","    return filtered_image\n","\n","\n","def edge_detection(image):\n","    sobel_edges = filters.sobel(image)\n","    scharr_edges = filters.scharr(image)\n","    prewitt_edges = filters.prewitt(image)\n","    gaussian_edges = filters.gaussian(image, sigma=1)\n","    roberts_edges = filters.roberts(image)\n","    return sobel_edges, scharr_edges, prewitt_edges, gaussian_edges, roberts_edges\n","\n","# Feature Extraction\n","gabor_feats = gabor_features(processed_image)\n","edges = edge_detection(processed_image)\n","\n","# Concatenate the feature arrays\n","features = np.concatenate((gabor_feats, *edges), axis=1)\n","\n","\n","# 4. Build a Numerical Dataset\n","def build_numerical_dataset(features):\n","    # Convert features into a numerical dataset\n","    numerical_dataset = np.array(features)\n","\n","    return numerical_dataset\n","\n","# 5. Dimensional Reduction\n","def dimensional_reduction(features, labels):\n","    pca = PCA(n_components=2)  # Reduce to 2 principal components\n","    pca_features = pca.fit_transform(features)\n","\n","    lda = LinearDiscriminantAnalysis(n_components=1)  # Reduce to 1 linear discriminant\n","    lda_features = lda.fit_transform(features, labels)\n","\n","    return pca_features, lda_features\n","\n","# 6. Feature Selection\n","def feature_selection(features, labels):\n","    selector = SelectKBest(score_func=f_classif, k=5)  # Select top 5 features\n","    selected_features = selector.fit_transform(features, labels)\n","    return selected_features\n","\n","# 7. Classification\n","def classify(features, labels):\n","    gb_classifier = GradientBoostingClassifier()  # Gradient Boosting\n","    gb_classifier.fit(features, labels)\n","\n","    rf_classifier = RandomForestClassifier()  # Random Forest\n","    rf_classifier.fit(features, labels)\n","\n","    svm_classifier = SVC()  # Support Vector Machine\n","    svm_classifier.fit(features, labels)\n","\n","    return gb_classifier, rf_classifier, svm_classifier\n","\n","# Example usage:\n","# Load image\n","image = cv2.imread('/content/drive/MyDrive/Final Year Project - Lung Cancer Prediction/Datasets/CT_Original/test/Cancerous/Cancerous107.jpg', cv2.IMREAD_GRAYSCALE)\n","\n","# Pre-processing\n","processed_image = image_preprocessing(image)\n","\n","# Segmentation\n","segmented_image = watershed_segmentation(processed_image)\n","\n","# Feature Extraction\n","gabor_feats = gabor_features(processed_image)\n","edges = edge_detection(processed_image)\n","\n","# Dataset Building\n","dataset = build_numerical_dataset(features)\n","\n","# Dimensional Reduction\n","labels = ['Cancerous', 'Non-Cancerous']\n","pca_features, lda_features = dimensional_reduction(dataset, labels)\n","\n","# Feature Selection\n","selected_features = feature_selection(dataset, labels)\n","\n","# Classification\n","gb_classifier, rf_classifier, svm_classifier = classify(selected_features, labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"IeOA9rGFiBHo","executionInfo":{"status":"error","timestamp":1709257562229,"user_tz":-330,"elapsed":3017,"user":{"displayName":"Agneeshwaran N M","userId":"06849285604708332594"}},"outputId":"57c65e55-548a-42b8-c71d-7856694b8fc8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'processed_image' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-41430f20baf0>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Feature Extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mgabor_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgabor_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'processed_image' is not defined"]}]}]}